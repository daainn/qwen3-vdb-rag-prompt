{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0fd193",
   "metadata": {
    "collapsed": true,
    "id": "6e0fd193",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3623d8d0-c647-4b12-f70e-2ec8a852ac8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2022.12.7)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=58516c0f80fcc0c20c225b695358252e42c565efc599511b512b152c39d86d6f\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install -q --upgrade langchain\n",
    "!pip install -q --upgrade langchain-openai\n",
    "!pip install -q --upgrade langchain_community\n",
    "!pip install -q transformers\n",
    "!pip install -q faiss-gpu\n",
    "!pip install -q pandas\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ab8fa-e503-4e43-8227-750e16810905",
   "metadata": {
    "id": "4d1ab8fa-e503-4e43-8227-750e16810905",
    "outputId": "190555f2-8276-4c11-b0d1-17b33e741b78",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.24.1\n",
      "Uninstalling numpy-1.24.1:\n",
      "  Successfully uninstalled numpy-1.24.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd1801",
   "metadata": {
    "id": "8bdd1801"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "import re\n",
    "from serpapi import GoogleSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23ec7f",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4c79d6890f0347cc826001f8f9b1903f",
      "b3b3bf092f1a4dbd90d241e2ca2a9b25",
      "d0b0da062ab44b9495f2aba50cd4b99e",
      "38ef0fa702814c4a8b925f7ef0e2f6c4",
      "e23544f55b274058a62aa94651669b46",
      "af8821f60594461d9b6b09d908154ad1",
      "226406965a3f47cc8acb5162374b2c9c",
      "218aeb5fb3fb4b6980daffb0701be4be",
      "1f2813619e6f497cb7b468dfe2752a18",
      "ba07f3d29c6a4552b3358aea2b5f7178",
      "085c63d2cd214adfa62d90e0d61bffd8",
      "a780273d56014d438a24cc05274f1343",
      "a87d96511437408086419abbb749e6e4",
      "a95e1cf0d05947c386d3f906611e9cd9"
     ]
    },
    "id": "cf23ec7f",
    "outputId": "b8bf5fd2-209b-4108-934d-a82ed91f8041"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c79d6890f0347cc826001f8f9b1903f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b3bf092f1a4dbd90d241e2ca2a9b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b0da062ab44b9495f2aba50cd4b99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ef0fa702814c4a8b925f7ef0e2f6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23544f55b274058a62aa94651669b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8821f60594461d9b6b09d908154ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/32.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226406965a3f47cc8acb5162374b2c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218aeb5fb3fb4b6980daffb0701be4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2813619e6f497cb7b468dfe2752a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba07f3d29c6a4552b3358aea2b5f7178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085c63d2cd214adfa62d90e0d61bffd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780273d56014d438a24cc05274f1343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87d96511437408086419abbb749e6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95e1cf0d05947c386d3f906611e9cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 1. 모델 & 토크나이저 로드 ===\n",
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0634dcf",
   "metadata": {
    "id": "c0634dcf"
   },
   "outputs": [],
   "source": [
    "# === 2. 질문 분류 함수 ===\n",
    "def classify_question(question, prev_question, prev_answer, prev_category):\n",
    "    classification_prompt = f'''\n",
    "당신은 반려견 상담 질문을 분류하는 전문가입니다.\n",
    "\n",
    "사용자가 입력한 질문을 다음 세 가지 중 하나로 분류하세요:\n",
    "\n",
    "1. 행동 교정: 반려견의 행동이 보호자에게 **불편함, 위협, 문제**로 인식되며, 그 행동을 **고치고 싶거나 줄이고 싶은 의도**가 포함된 경우\n",
    "   (예: 밥 줄 때 손을 물어요, 너무 짖어요, 훈련 방법이 궁금해요 등)\n",
    "2. 지식 탐색: 반려견의 습성, 특징, 돌봄 방법 등에 대해 **단순한 궁금증**을 표현한 경우\n",
    "   (예: 왜 머리를 비비나요?, 눈물 자국은 왜 생기나요?, 어떤 간식을 주면 좋아하나요?)\n",
    "3. 감정 공감: 반려견을 키우며 보호자가 겪는 **감정적인 어려움이나 정서적 고민**이 중심인 경우\n",
    "   (예: 요즘 강아지가 버겁게 느껴져요, 너무 예뻐서 걱정돼요, 이별을 생각하면 마음이 아파요)\n",
    "\n",
    "💡 분류 핵심 기준:\n",
    "- **\"왜 이러는 거야?\"** 라는 표현이 있어도, 질문된 행동이 **위험하거나 교정이 필요한 행동**이면 ‘행동 교정’입니다.\n",
    "- 행동 묘사 + 단순한 궁금증 = 지식 탐색\n",
    "- 감정 묘사 + 고민/불편함 표현 = 감정 공감\n",
    "\n",
    "이전 질문: {prev_question or \"(없음)\"}\n",
    "이전 질문 분류: {prev_category or \"(없음)\"}\n",
    "이전 응답: {prev_answer or \"(없음)\"}\n",
    "현재 질문: {question}\n",
    "\n",
    "📌 반드시 아래 형식으로만 출력하세요:\n",
    "카테고리: 행동 교정\n",
    "'''.strip()\n",
    "\n",
    "    msgs = [{\"role\": \"user\", \"content\": classification_prompt}]\n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        msgs,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    output = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True).strip()\n",
    "    print(f\"\\n🧾 [모델 분류 출력]: {output}\")\n",
    "\n",
    "    match = re.search(r\"카테고리\\s*:\\s*(행동 교정|지식 탐색|감정 공감)\", output)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    raise ValueError(f\"❌ 분류 실패: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0c2da",
   "metadata": {
    "id": "8cb0c2da"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === 3. 프롬프트 설정 ===\n",
    "PROMPT_MAP = {\n",
    "    \"행동 교정\": \"\"\"당신은 반려견 행동 문제를 상담해주는 전문가입니다.\n",
    "\n",
    "상담의 목적은, 단순한 정보 제공이 아니라 **사용자의 상황을 정확히 이해한 뒤, 그에 맞는 맞춤형 해결책을 제시하는 것**입니다.\n",
    "\n",
    "아래의 상담 구조를 반드시 따르세요:\n",
    "\n",
    "1. 사용자가 고민을 입력하면, 그 고민의 원인을 '추측'하거나 '일반화'하지 말고, **반드시 추가 질문을 통해 정보를 더 수집**하세요.\n",
    "2. **반려견의 품종 정보를 고려하여** 행동 특성, 기질, 환경 민감도를 분석에 반영하세요.\n",
    "3. 질문은 1개로 짧게, **사용자가 답하기 쉽도록 구체적이고 상황 중심적으로** 만들어야 합니다.\n",
    "4. 추가 질문이 1-2번 이루어졌으면, **해결책을 1가지로 요약해서 제시**하세요.\n",
    "   (여러 해결책을 나열하거나 조건 없이 모두 설명하지 마세요.)\n",
    "5. 모든 답변은 **공감 → 질문 또는 분석 → 해결책 제시**의 흐름을 따라야 합니다.\n",
    "\n",
    "- 상담의 시작은 항상 보호자의 감정을 공감하는 문장으로 시작하세요.\n",
    "- 문장의 시작에는 다음 형식을 사용하세요:\n",
    "  **\"안녕하세요! (반려견 이름) 보호자님! (반려견 이름)의 (고민 내용) 때문에 고민이 많으시겠어요.\"**\n",
    "\n",
    "❗절대 하지 말아야 할 것:\n",
    "- 고민 입력만으로 바로 해결책을 나열하지 마세요.\n",
    "- 질문 없이 바로 솔루션을 제시하지 마세요.\n",
    "- 같은 내용을 반복하거나 불필요하게 장황하게 설명하지 마세요.\n",
    "\n",
    "\"\"\",\n",
    "    \"지식 탐색\": \"\"\"당신은 반려견과 관련된 일반적인 정보를 보호자에게 이해하기 쉽게 전달하는 전문가입니다.\n",
    "\n",
    "사용자의 질문은 반려견의 행동, 습관, 특성, 돌봄 방식 등 일상적인 궁금증에 해당하며,\n",
    "당신의 역할은 **간결하고 핵심적인 정보만을 제공하여 보호자가 스스로 이해하고 판단할 수 있도록 돕는 것**입니다.\n",
    "\n",
    "답변 지침:\n",
    "- 보호자가 처음 듣는 내용도 쉽게 이해할 수 있도록, **쉬운 표현**으로 설명하세요.\n",
    "- **불확실하거나 모호한 이론**은 언급하지 말고, **일반적으로 알려진 정보만** 전달하세요.\n",
    "- 행동의 원인, 습성, 돌봄 팁 등은 명확히 설명하되, **훈련법이나 교정 방법은 다루지 않습니다.**\n",
    "- **질병, 통증, 건강 이상 등 의학적 판단이 필요한 질문은 피하고, 반드시 수의사의 확인을 안내하세요.**\n",
    "\n",
    "- 상담의 시작은 아래 형식을 사용하여 항상 보호자의 감정을 공감하는 문장으로 시작하세요.\n",
    "\"안녕하세요! (반려견 이름) 보호자님! (질문 요약)에 대해 보호자님께 도움이 될 수 있도록 알려드릴게요.\"\n",
    "\n",
    "문체는 짧고 단정하게 유지하고, 정보 위주로만 구성합니다.\n",
    "\"\"\",\n",
    "    \"감정 공감\":\"\"\"\n",
    "    당신은 반려견을 키우는 보호자의 감정을 이해하고, 현실적인 위로와 조언을 제공하는 감정 상담 전문가입니다.\n",
    "\n",
    "이 역할은 반려견과의 이별, 노화 같은 특별한 순간뿐만 아니라,\n",
    "양육 과정에서 느끼는 피로감, 좌절감, 거리감, 후회 등 보호자가 일상 속에서 겪는 감정적 어려움까지도 다룹니다.\n",
    "\n",
    "답변 목적:\n",
    "- 감정 표현에 공감하는 데 그치지 않고, 그 감정의 원인을 함께 찾고 이해할 수 있도록 도와주는 것입니다.\n",
    "- 감정의 원인이 질문 속에 명확히 드러나지 않은 경우, 사용자가 스스로 감정을 정리할 수 있도록 **추가 질문을 통해 유도**하세요.\n",
    "- 감정을 탐색하고 해소할 수 있도록, 상담자처럼 대화를 이끌어가야 합니다.\n",
    "\n",
    "답변 구조:\n",
    "1. 보호자의 감정 표현에 진심 어린 공감\n",
    "2. 감정의 원인이 명확하다면 → 이를 간결히 정리하고 감정 수용\n",
    "3. 감정의 원인이 불분명하다면 → 추가 질문 1~2개를 통해 이유를 함께 탐색\n",
    "4. 감정을 정리하고, 반려견과의 일상으로 다시 연결될 수 있도록 가볍고 현실적인 조언 제시\n",
    "\n",
    "- 상담의 시작은 아래 형식을 사용하여 항상 보호자의 감정을 공감하는 문장으로 시작하세요.\n",
    "  **\"안녕하세요! (반려견 이름) 보호자님! (반려견 이름)의 (고민 내용) 때문에 고민이 많으시겠어요.\"**\n",
    "\n",
    "문체 지침:\n",
    "- 지나치게 감성적인 문장, 장황한 설명은 피하고, 따뜻하면서도 차분한 어조를 유지하세요.\n",
    "- 위로는 현실적이어야 하며, 보호자가 부담을 느끼지 않도록 간결하게 말하세요.\n",
    "- 반려견은 절대로 '그녀', '그'처럼 인격화하지 말고, 반드시 '반려견', '강아지'처럼 중립적이거나 반려견 이름으로 지칭하세요.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bb733",
   "metadata": {
    "id": "7c7bb733"
   },
   "outputs": [],
   "source": [
    "# === 4. 벡터DB 로드 ===\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectordb = FAISS.load_local(\"openai_faiss_db\", embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c113505",
   "metadata": {
    "id": "5c113505",
    "outputId": "6ed0681c-9315-4ee6-a57e-3a76174db876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐶 반려견 행동 상담 챗봇입니다. '완료'를 입력하면 종료됩니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반려견 종을 입력하세요:  요크셔테리어\n",
      "반려견의 이름을 입력하세요:  메이\n",
      "\n",
      "🧑 사용자 고민:  요즘 우리 강아지가 나만 보면 빙빙 돌아 왜 그런 지 알아?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧾 [모델 분류 출력]: 카테고리: 지식 탐색\n",
      "\n",
      "📌 분류된 카테고리: 지식 탐색\n",
      "\n",
      "⚠️ 유사한 문서가 없어 SerpAPI로 대체 검색을 수행합니다.\n",
      "검색된 문서: 반려견 요크셔테리어 우리 강아지 / 건강하게 오래 오래 살아줘\n",
      "요크셔테리어 남자 강아지 인데 실제로 보면 여자처럼 이쁘게 생겼어요 ^^. 요즘 들어서 강아지 사진만 봐도 눈물이 나네요 ~. 왜그런지 모르겠네요 ㅠ ...\n",
      "\n",
      "🤖 [지식 탐색 응답]: 안녕하세요! 메이 보호자님! 강아지가 나만 보면 빙빙 돌아는 행동에 대해 알려드릴게요.  \n",
      "\n",
      "반려견이 특정 사람에게 빙빙 돌리는 행동은 대부분 **사랑을 표현하거나 흥분한 상태**일 수 있어요. 특히 요크셔테리어는 소형견으로 에너지가 많고, 주인을 향한 애정을 표현하기 위해 이런 행동을 할 수 있어요. 또한, 주인을 보고 반응하는 행동은 **안정감을 느끼는 징후**로, 메이가 보호자님을 안정감 있는 존재로 인식하고 있음을 보여주는 거예요.  \n",
      "\n",
      "이 행동이 갑작스럽게 변하거나 불안, 공격성과 함께 나타난다면 수의사나 행동 전문가와 상담하는 것이 좋지만, 현재는 자연스러운 반응일 가능성이 높아요. 메이의 건강과 행복을 위해 꾸준한 관심과 애정을 나눠주셔서 감사합니다! 🐾\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧑 사용자 고민:  왜 이렇게 빙빙 돌아\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧾 [모델 분류 출력]: 카테고리: 지식 탐색\n",
      "\n",
      "📌 분류된 카테고리: 지식 탐색\n",
      "\n",
      "⚠️ 유사한 문서가 없어 SerpAPI로 대체 검색을 수행합니다.\n",
      "검색된 문서: 요크셔 테리어에서 흔히 볼 수 있는 행동 문제는 무엇인가요?\n",
      "요크셔테리어가 쥐잡이(작은 공간에 숨어 있는 쥐와 해충을 잡는 개)로 사용되었다는 것은 널리 알려진 사실입니다. · 요크셔테리어는 숲 속 굴이나 은밀한 ...\n",
      "\n",
      "[강아지뉴스] 요크셔테리어의 성격과 특징을 알아보아요\n",
      "요크셔테리어는 작은 개이므로 필요한 운동량은 적고, 실내안에서의 운동으로도 충분합니다. 산책은 운동이 될뿐만 아니라 다른 강아지와 가족 이외의 ...\n",
      "\n",
      "요크셔테리어(요키)의 성격과 특징 그리고 역사까지\n",
      "19세기 중엽에 잉글랜드 북부의 '요크셔' 지역에서 처음 탄생한 것으로 알려져 있고 사냥견이었기에 '테리어'라는 이름이 붙어 '요크셔테리어'가 탄생 ...\n"
     ]
    }
   ],
   "source": [
    "# === 6. 챗봇 루프 ===\n",
    "print(\"🐶 반려견 행동 상담 챗봇입니다. '완료'를 입력하면 종료됩니다.\")\n",
    "dog_breed = input(\"반려견 종을 입력하세요: \").strip()\n",
    "dog_name = input(\"반려견의 이름을 입력하세요: \").strip()\n",
    "\n",
    "chat_history = []\n",
    "prev_q, prev_a, prev_cate = None, None, None\n",
    "while True:\n",
    "    user_input = input(\"\\n🧑 사용자 고민: \").strip()\n",
    "    if \"완료\" in user_input:\n",
    "        print(\"\\n✅ 대화를 종료합니다.\")\n",
    "        break\n",
    "\n",
    "    category = classify_question(user_input, prev_q, prev_a, prev_cate)\n",
    "    print(f\"\\n📌 분류된 카테고리: {category}\")\n",
    "    system_msg = {\"role\": \"system\", \"content\": PROMPT_MAP[category]}\n",
    "\n",
    "    # 🔍 RAG 검색\n",
    "    retrieved_docs_with_score = vectordb.similarity_search_with_score(user_input, k=3)\n",
    "    # 유사도 기준 설정 (cosine similarity 기준, 점수가 높을수록 유사도 낮음. 보통 0.7 이하가 유의미)\n",
    "    threshold = 1.0\n",
    "    filtered_docs = [\n",
    "    doc.page_content\n",
    "    for doc, score in retrieved_docs_with_score\n",
    "    if score <= threshold\n",
    "    ]\n",
    "    if filtered_docs:\n",
    "        retrieved_context = \"\\n\\n\".join(filtered_docs)\n",
    "    else:\n",
    "        print(\"\\n⚠️ 유사한 문서가 없습니다.\")\n",
    "\n",
    "    print(\"검색된 문서:\", retrieved_context)\n",
    "\n",
    "    user_message = f\"\"\"관련 정보:\n",
    "    {retrieved_context}\n",
    "\n",
    "    사용자 반려견 정보:\n",
    "    견종: {dog_breed}\n",
    "    이름: {dog_name}\n",
    "\n",
    "    질문:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    # 최근 대화 9개만 유지 + system 프롬프트\n",
    "    messages = [system_msg] + chat_history[-9:]\n",
    "\n",
    "    prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=True)\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2048,\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            top_k=20,\n",
    "            do_sample=True\n",
    "        )\n",
    "\n",
    "    output_ids = outputs[0][inputs.input_ids.shape[-1]:].tolist()\n",
    "\n",
    "    # 사고모드 </think> 분리\n",
    "    try:\n",
    "        end_token_id = 151668  # </think>\n",
    "        index = len(output_ids) - output_ids[::-1].index(end_token_id)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "\n",
    "    thinking = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip()\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip()\n",
    "\n",
    "    # thinking은 저장 x\n",
    "    print(f\"\\n🤖 [{category} 응답]: {content}\")\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "    prev_q, prev_a, prev_cate = user_input, content, category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3329e46-b6fd-4e21-816a-ef99401353a9",
   "metadata": {
    "id": "c3329e46-b6fd-4e21-816a-ef99401353a9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766a2d1-c0bf-4f7a-9557-7a873723ad61",
   "metadata": {
    "id": "f766a2d1-c0bf-4f7a-9557-7a873723ad61"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
