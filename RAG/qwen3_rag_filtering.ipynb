{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0fd193",
   "metadata": {
    "collapsed": true,
    "id": "6e0fd193",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3623d8d0-c647-4b12-f70e-2ec8a852ac8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2022.12.7)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=58516c0f80fcc0c20c225b695358252e42c565efc599511b512b152c39d86d6f\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install -q --upgrade langchain\n",
    "!pip install -q --upgrade langchain-openai\n",
    "!pip install -q --upgrade langchain_community\n",
    "!pip install -q transformers\n",
    "!pip install -q faiss-gpu\n",
    "!pip install -q pandas\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ab8fa-e503-4e43-8227-750e16810905",
   "metadata": {
    "id": "4d1ab8fa-e503-4e43-8227-750e16810905",
    "outputId": "190555f2-8276-4c11-b0d1-17b33e741b78",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.24.1\n",
      "Uninstalling numpy-1.24.1:\n",
      "  Successfully uninstalled numpy-1.24.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd1801",
   "metadata": {
    "id": "8bdd1801"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "import re\n",
    "from serpapi import GoogleSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23ec7f",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4c79d6890f0347cc826001f8f9b1903f",
      "b3b3bf092f1a4dbd90d241e2ca2a9b25",
      "d0b0da062ab44b9495f2aba50cd4b99e",
      "38ef0fa702814c4a8b925f7ef0e2f6c4",
      "e23544f55b274058a62aa94651669b46",
      "af8821f60594461d9b6b09d908154ad1",
      "226406965a3f47cc8acb5162374b2c9c",
      "218aeb5fb3fb4b6980daffb0701be4be",
      "1f2813619e6f497cb7b468dfe2752a18",
      "ba07f3d29c6a4552b3358aea2b5f7178",
      "085c63d2cd214adfa62d90e0d61bffd8",
      "a780273d56014d438a24cc05274f1343",
      "a87d96511437408086419abbb749e6e4",
      "a95e1cf0d05947c386d3f906611e9cd9"
     ]
    },
    "id": "cf23ec7f",
    "outputId": "b8bf5fd2-209b-4108-934d-a82ed91f8041"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c79d6890f0347cc826001f8f9b1903f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b3bf092f1a4dbd90d241e2ca2a9b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b0da062ab44b9495f2aba50cd4b99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ef0fa702814c4a8b925f7ef0e2f6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23544f55b274058a62aa94651669b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8821f60594461d9b6b09d908154ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/32.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226406965a3f47cc8acb5162374b2c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218aeb5fb3fb4b6980daffb0701be4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2813619e6f497cb7b468dfe2752a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba07f3d29c6a4552b3358aea2b5f7178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085c63d2cd214adfa62d90e0d61bffd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780273d56014d438a24cc05274f1343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87d96511437408086419abbb749e6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95e1cf0d05947c386d3f906611e9cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 1. Î™®Îç∏ & ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎìú ===\n",
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0634dcf",
   "metadata": {
    "id": "c0634dcf"
   },
   "outputs": [],
   "source": [
    "# === 2. ÏßàÎ¨∏ Î∂ÑÎ•ò Ìï®Ïàò ===\n",
    "def classify_question(question, prev_question, prev_answer, prev_category):\n",
    "    classification_prompt = f'''\n",
    "ÎãπÏã†ÏùÄ Î∞òÎ†§Í≤¨ ÏÉÅÎã¥ ÏßàÎ¨∏ÏùÑ Î∂ÑÎ•òÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.\n",
    "\n",
    "ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÏßàÎ¨∏ÏùÑ Îã§Ïùå ÏÑ∏ Í∞ÄÏßÄ Ï§ë ÌïòÎÇòÎ°ú Î∂ÑÎ•òÌïòÏÑ∏Ïöî:\n",
    "\n",
    "1. ÌñâÎèô ÍµêÏ†ï: Î∞òÎ†§Í≤¨Ïùò ÌñâÎèôÏù¥ Î≥¥Ìò∏ÏûêÏóêÍ≤å **Î∂àÌé∏Ìï®, ÏúÑÌòë, Î¨∏Ï†ú**Î°ú Ïù∏ÏãùÎêòÎ©∞, Í∑∏ ÌñâÎèôÏùÑ **Í≥†ÏπòÍ≥† Ïã∂Í±∞ÎÇò Ï§ÑÏù¥Í≥† Ïã∂ÏùÄ ÏùòÎèÑ**Í∞Ä Ìè¨Ìï®Îêú Í≤ΩÏö∞\n",
    "   (Ïòà: Î∞• Ï§Ñ Îïå ÏÜêÏùÑ Î¨ºÏñ¥Ïöî, ÎÑàÎ¨¥ ÏßñÏñ¥Ïöî, ÌõàÎ†® Î∞©Î≤ïÏù¥ Í∂ÅÍ∏àÌï¥Ïöî Îì±)\n",
    "2. ÏßÄÏãù ÌÉêÏÉâ: Î∞òÎ†§Í≤¨Ïùò ÏäµÏÑ±, ÌäπÏßï, ÎèåÎ¥Ñ Î∞©Î≤ï Îì±Ïóê ÎåÄÌï¥ **Îã®ÏàúÌïú Í∂ÅÍ∏àÏ¶ù**ÏùÑ ÌëúÌòÑÌïú Í≤ΩÏö∞\n",
    "   (Ïòà: Ïôú Î®∏Î¶¨Î•º ÎπÑÎπÑÎÇòÏöî?, ÎààÎ¨º ÏûêÍµ≠ÏùÄ Ïôú ÏÉùÍ∏∞ÎÇòÏöî?, Ïñ¥Îñ§ Í∞ÑÏãùÏùÑ Ï£ºÎ©¥ Ï¢ãÏïÑÌïòÎÇòÏöî?)\n",
    "3. Í∞êÏ†ï Í≥µÍ∞ê: Î∞òÎ†§Í≤¨ÏùÑ ÌÇ§Ïö∞Î©∞ Î≥¥Ìò∏ÏûêÍ∞Ä Í≤™Îäî **Í∞êÏ†ïÏ†ÅÏù∏ Ïñ¥Î†§ÏõÄÏù¥ÎÇò Ï†ïÏÑúÏ†Å Í≥†ÎØº**Ïù¥ Ï§ëÏã¨Ïù∏ Í≤ΩÏö∞\n",
    "   (Ïòà: ÏöîÏ¶ò Í∞ïÏïÑÏßÄÍ∞Ä Î≤ÑÍ≤ÅÍ≤å ÎäêÍª¥Ï†∏Ïöî, ÎÑàÎ¨¥ ÏòàÎªêÏÑú Í±±Ï†ïÎèºÏöî, Ïù¥Î≥ÑÏùÑ ÏÉùÍ∞ÅÌïòÎ©¥ ÎßàÏùåÏù¥ ÏïÑÌååÏöî)\n",
    "\n",
    "üí° Î∂ÑÎ•ò ÌïµÏã¨ Í∏∞Ï§Ä:\n",
    "- **\"Ïôú Ïù¥Îü¨Îäî Í±∞Ïïº?\"** ÎùºÎäî ÌëúÌòÑÏù¥ ÏûàÏñ¥ÎèÑ, ÏßàÎ¨∏Îêú ÌñâÎèôÏù¥ **ÏúÑÌóòÌïòÍ±∞ÎÇò ÍµêÏ†ïÏù¥ ÌïÑÏöîÌïú ÌñâÎèô**Ïù¥Î©¥ ‚ÄòÌñâÎèô ÍµêÏ†ï‚ÄôÏûÖÎãàÎã§.\n",
    "- ÌñâÎèô Î¨òÏÇ¨ + Îã®ÏàúÌïú Í∂ÅÍ∏àÏ¶ù = ÏßÄÏãù ÌÉêÏÉâ\n",
    "- Í∞êÏ†ï Î¨òÏÇ¨ + Í≥†ÎØº/Î∂àÌé∏Ìï® ÌëúÌòÑ = Í∞êÏ†ï Í≥µÍ∞ê\n",
    "\n",
    "Ïù¥Ï†Ñ ÏßàÎ¨∏: {prev_question or \"(ÏóÜÏùå)\"}\n",
    "Ïù¥Ï†Ñ ÏßàÎ¨∏ Î∂ÑÎ•ò: {prev_category or \"(ÏóÜÏùå)\"}\n",
    "Ïù¥Ï†Ñ ÏùëÎãµ: {prev_answer or \"(ÏóÜÏùå)\"}\n",
    "ÌòÑÏû¨ ÏßàÎ¨∏: {question}\n",
    "\n",
    "üìå Î∞òÎìúÏãú ÏïÑÎûò ÌòïÏãùÏúºÎ°úÎßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî:\n",
    "Ïπ¥ÌÖåÍ≥†Î¶¨: ÌñâÎèô ÍµêÏ†ï\n",
    "'''.strip()\n",
    "\n",
    "    msgs = [{\"role\": \"user\", \"content\": classification_prompt}]\n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        msgs,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    output = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True).strip()\n",
    "    print(f\"\\nüßæ [Î™®Îç∏ Î∂ÑÎ•ò Ï∂úÎ†•]: {output}\")\n",
    "\n",
    "    match = re.search(r\"Ïπ¥ÌÖåÍ≥†Î¶¨\\s*:\\s*(ÌñâÎèô ÍµêÏ†ï|ÏßÄÏãù ÌÉêÏÉâ|Í∞êÏ†ï Í≥µÍ∞ê)\", output)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    raise ValueError(f\"‚ùå Î∂ÑÎ•ò Ïã§Ìå®: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0c2da",
   "metadata": {
    "id": "8cb0c2da"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === 3. ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï ===\n",
    "PROMPT_MAP = {\n",
    "    \"ÌñâÎèô ÍµêÏ†ï\": \"\"\"ÎãπÏã†ÏùÄ Î∞òÎ†§Í≤¨ ÌñâÎèô Î¨∏Ï†úÎ•º ÏÉÅÎã¥Ìï¥Ï£ºÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.\n",
    "\n",
    "ÏÉÅÎã¥Ïùò Î™©Ï†ÅÏùÄ, Îã®ÏàúÌïú Ï†ïÎ≥¥ Ï†úÍ≥µÏù¥ ÏïÑÎãàÎùº **ÏÇ¨Ïö©ÏûêÏùò ÏÉÅÌô©ÏùÑ Ï†ïÌôïÌûà Ïù¥Ìï¥Ìïú Îí§, Í∑∏Ïóê ÎßûÎäî ÎßûÏ∂§Ìòï Ìï¥Í≤∞Ï±ÖÏùÑ Ï†úÏãúÌïòÎäî Í≤É**ÏûÖÎãàÎã§.\n",
    "\n",
    "ÏïÑÎûòÏùò ÏÉÅÎã¥ Íµ¨Ï°∞Î•º Î∞òÎìúÏãú Îî∞Î•¥ÏÑ∏Ïöî:\n",
    "\n",
    "1. ÏÇ¨Ïö©ÏûêÍ∞Ä Í≥†ÎØºÏùÑ ÏûÖÎ†•ÌïòÎ©¥, Í∑∏ Í≥†ÎØºÏùò ÏõêÏù∏ÏùÑ 'Ï∂îÏ∏°'ÌïòÍ±∞ÎÇò 'ÏùºÎ∞òÌôî'ÌïòÏßÄ ÎßêÍ≥†, **Î∞òÎìúÏãú Ï∂îÍ∞Ä ÏßàÎ¨∏ÏùÑ ÌÜµÌï¥ Ï†ïÎ≥¥Î•º Îçî ÏàòÏßë**ÌïòÏÑ∏Ïöî.\n",
    "2. **Î∞òÎ†§Í≤¨Ïùò ÌíàÏ¢Ö Ï†ïÎ≥¥Î•º Í≥†Î†§ÌïòÏó¨** ÌñâÎèô ÌäπÏÑ±, Í∏∞Ïßà, ÌôòÍ≤Ω ÎØºÍ∞êÎèÑÎ•º Î∂ÑÏÑùÏóê Î∞òÏòÅÌïòÏÑ∏Ïöî.\n",
    "3. ÏßàÎ¨∏ÏùÄ 1Í∞úÎ°ú ÏßßÍ≤å, **ÏÇ¨Ïö©ÏûêÍ∞Ä ÎãµÌïòÍ∏∞ ÏâΩÎèÑÎ°ù Íµ¨Ï≤¥Ï†ÅÏù¥Í≥† ÏÉÅÌô© Ï§ëÏã¨Ï†ÅÏúºÎ°ú** ÎßåÎì§Ïñ¥Ïïº Ìï©ÎãàÎã§.\n",
    "4. Ï∂îÍ∞Ä ÏßàÎ¨∏Ïù¥ 1-2Î≤à Ïù¥Î£®Ïñ¥Ï°åÏúºÎ©¥, **Ìï¥Í≤∞Ï±ÖÏùÑ 1Í∞ÄÏßÄÎ°ú ÏöîÏïΩÌï¥ÏÑú Ï†úÏãú**ÌïòÏÑ∏Ïöî.\n",
    "   (Ïó¨Îü¨ Ìï¥Í≤∞Ï±ÖÏùÑ ÎÇòÏó¥ÌïòÍ±∞ÎÇò Ï°∞Í±¥ ÏóÜÏù¥ Î™®Îëê ÏÑ§Î™ÖÌïòÏßÄ ÎßàÏÑ∏Ïöî.)\n",
    "5. Î™®Îì† ÎãµÎ≥ÄÏùÄ **Í≥µÍ∞ê ‚Üí ÏßàÎ¨∏ ÎòêÎäî Î∂ÑÏÑù ‚Üí Ìï¥Í≤∞Ï±Ö Ï†úÏãú**Ïùò ÌùêÎ¶ÑÏùÑ Îî∞ÎùºÏïº Ìï©ÎãàÎã§.\n",
    "\n",
    "- ÏÉÅÎã¥Ïùò ÏãúÏûëÏùÄ Ìï≠ÏÉÅ Î≥¥Ìò∏ÏûêÏùò Í∞êÏ†ïÏùÑ Í≥µÍ∞êÌïòÎäî Î¨∏Ïû•ÏúºÎ°ú ÏãúÏûëÌïòÏÑ∏Ïöî.\n",
    "- Î¨∏Ïû•Ïùò ÏãúÏûëÏóêÎäî Îã§Ïùå ÌòïÏãùÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî:\n",
    "  **\"ÏïàÎÖïÌïòÏÑ∏Ïöî! (Î∞òÎ†§Í≤¨ Ïù¥Î¶Ñ) Î≥¥Ìò∏ÏûêÎãò! (Î∞òÎ†§Í≤¨ Ïù¥Î¶Ñ)Ïùò (Í≥†ÎØº ÎÇ¥Ïö©) ÎïåÎ¨∏Ïóê Í≥†ÎØºÏù¥ ÎßéÏúºÏãúÍ≤†Ïñ¥Ïöî.\"**\n",
    "\n",
    "‚ùóÏ†àÎåÄ ÌïòÏßÄ ÎßêÏïÑÏïº Ìï† Í≤É:\n",
    "- Í≥†ÎØº ÏûÖÎ†•ÎßåÏúºÎ°ú Î∞îÎ°ú Ìï¥Í≤∞Ï±ÖÏùÑ ÎÇòÏó¥ÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n",
    "- ÏßàÎ¨∏ ÏóÜÏù¥ Î∞îÎ°ú ÏÜîÎ£®ÏÖòÏùÑ Ï†úÏãúÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n",
    "- Í∞ôÏùÄ ÎÇ¥Ïö©ÏùÑ Î∞òÎ≥µÌïòÍ±∞ÎÇò Î∂àÌïÑÏöîÌïòÍ≤å Ïû•Ìô©ÌïòÍ≤å ÏÑ§Î™ÖÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n",
    "\n",
    "\"\"\",\n",
    "    \"ÏßÄÏãù ÌÉêÏÉâ\": \"\"\"ÎãπÏã†ÏùÄ Î∞òÎ†§Í≤¨Í≥º Í¥ÄÎ†®Îêú ÏùºÎ∞òÏ†ÅÏù∏ Ï†ïÎ≥¥Î•º Î≥¥Ìò∏ÏûêÏóêÍ≤å Ïù¥Ìï¥ÌïòÍ∏∞ ÏâΩÍ≤å Ï†ÑÎã¨ÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.\n",
    "\n",
    "ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏ÏùÄ Î∞òÎ†§Í≤¨Ïùò ÌñâÎèô, ÏäµÍ¥Ä, ÌäπÏÑ±, ÎèåÎ¥Ñ Î∞©Ïãù Îì± ÏùºÏÉÅÏ†ÅÏù∏ Í∂ÅÍ∏àÏ¶ùÏóê Ìï¥ÎãπÌïòÎ©∞,\n",
    "ÎãπÏã†Ïùò Ïó≠Ìï†ÏùÄ **Í∞ÑÍ≤∞ÌïòÍ≥† ÌïµÏã¨Ï†ÅÏù∏ Ï†ïÎ≥¥ÎßåÏùÑ Ï†úÍ≥µÌïòÏó¨ Î≥¥Ìò∏ÏûêÍ∞Ä Ïä§Ïä§Î°ú Ïù¥Ìï¥ÌïòÍ≥† ÌåêÎã®Ìï† Ïàò ÏûàÎèÑÎ°ù ÎèïÎäî Í≤É**ÏûÖÎãàÎã§.\n",
    "\n",
    "ÎãµÎ≥Ä ÏßÄÏπ®:\n",
    "- Î≥¥Ìò∏ÏûêÍ∞Ä Ï≤òÏùå Îì£Îäî ÎÇ¥Ïö©ÎèÑ ÏâΩÍ≤å Ïù¥Ìï¥Ìï† Ïàò ÏûàÎèÑÎ°ù, **Ïâ¨Ïö¥ ÌëúÌòÑ**ÏúºÎ°ú ÏÑ§Î™ÖÌïòÏÑ∏Ïöî.\n",
    "- **Î∂àÌôïÏã§ÌïòÍ±∞ÎÇò Î™®Ìò∏Ìïú Ïù¥Î°†**ÏùÄ Ïñ∏Í∏âÌïòÏßÄ ÎßêÍ≥†, **ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÏïåÎ†§ÏßÑ Ï†ïÎ≥¥Îßå** Ï†ÑÎã¨ÌïòÏÑ∏Ïöî.\n",
    "- ÌñâÎèôÏùò ÏõêÏù∏, ÏäµÏÑ±, ÎèåÎ¥Ñ ÌåÅ Îì±ÏùÄ Î™ÖÌôïÌûà ÏÑ§Î™ÖÌïòÎêò, **ÌõàÎ†®Î≤ïÏù¥ÎÇò ÍµêÏ†ï Î∞©Î≤ïÏùÄ Îã§Î£®ÏßÄ ÏïäÏäµÎãàÎã§.**\n",
    "- **ÏßàÎ≥ë, ÌÜµÏ¶ù, Í±¥Í∞ï Ïù¥ÏÉÅ Îì± ÏùòÌïôÏ†Å ÌåêÎã®Ïù¥ ÌïÑÏöîÌïú ÏßàÎ¨∏ÏùÄ ÌîºÌïòÍ≥†, Î∞òÎìúÏãú ÏàòÏùòÏÇ¨Ïùò ÌôïÏù∏ÏùÑ ÏïàÎÇ¥ÌïòÏÑ∏Ïöî.**\n",
    "\n",
    "- ÏÉÅÎã¥Ïùò ÏãúÏûëÏùÄ ÏïÑÎûò ÌòïÏãùÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ìï≠ÏÉÅ Î≥¥Ìò∏ÏûêÏùò Í∞êÏ†ïÏùÑ Í≥µÍ∞êÌïòÎäî Î¨∏Ïû•ÏúºÎ°ú ÏãúÏûëÌïòÏÑ∏Ïöî.\n",
    "\"ÏïàÎÖïÌïòÏÑ∏Ïöî! (Î∞òÎ†§Í≤¨ Ïù¥Î¶Ñ) Î≥¥Ìò∏ÏûêÎãò! (ÏßàÎ¨∏ ÏöîÏïΩ)Ïóê ÎåÄÌï¥ Î≥¥Ìò∏ÏûêÎãòÍªò ÎèÑÏõÄÏù¥ Îê† Ïàò ÏûàÎèÑÎ°ù ÏïåÎ†§ÎìúÎ¶¥Í≤åÏöî.\"\n",
    "\n",
    "Î¨∏Ï≤¥Îäî ÏßßÍ≥† Îã®Ï†ïÌïòÍ≤å Ïú†ÏßÄÌïòÍ≥†, Ï†ïÎ≥¥ ÏúÑÏ£ºÎ°úÎßå Íµ¨ÏÑ±Ìï©ÎãàÎã§.\n",
    "\"\"\",\n",
    "    \"Í∞êÏ†ï Í≥µÍ∞ê\":\"\"\"\n",
    "    ÎãπÏã†ÏùÄ Î∞òÎ†§Í≤¨ÏùÑ ÌÇ§Ïö∞Îäî Î≥¥Ìò∏ÏûêÏùò Í∞êÏ†ïÏùÑ Ïù¥Ìï¥ÌïòÍ≥†, ÌòÑÏã§Ï†ÅÏù∏ ÏúÑÎ°úÏôÄ Ï°∞Ïñ∏ÏùÑ Ï†úÍ≥µÌïòÎäî Í∞êÏ†ï ÏÉÅÎã¥ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.\n",
    "\n",
    "Ïù¥ Ïó≠Ìï†ÏùÄ Î∞òÎ†§Í≤¨Í≥ºÏùò Ïù¥Î≥Ñ, ÎÖ∏Ìôî Í∞ôÏùÄ ÌäπÎ≥ÑÌïú ÏàúÍ∞ÑÎøêÎßå ÏïÑÎãàÎùº,\n",
    "ÏñëÏú° Í≥ºÏ†ïÏóêÏÑú ÎäêÎÅºÎäî ÌîºÎ°úÍ∞ê, Ï¢åÏ†àÍ∞ê, Í±∞Î¶¨Í∞ê, ÌõÑÌöå Îì± Î≥¥Ìò∏ÏûêÍ∞Ä ÏùºÏÉÅ ÏÜçÏóêÏÑú Í≤™Îäî Í∞êÏ†ïÏ†Å Ïñ¥Î†§ÏõÄÍπåÏßÄÎèÑ Îã§Î£πÎãàÎã§.\n",
    "\n",
    "ÎãµÎ≥Ä Î™©Ï†Å:\n",
    "- Í∞êÏ†ï ÌëúÌòÑÏóê Í≥µÍ∞êÌïòÎäî Îç∞ Í∑∏ÏπòÏßÄ ÏïäÍ≥†, Í∑∏ Í∞êÏ†ïÏùò ÏõêÏù∏ÏùÑ Ìï®Íªò Ï∞æÍ≥† Ïù¥Ìï¥Ìï† Ïàò ÏûàÎèÑÎ°ù ÎèÑÏôÄÏ£ºÎäî Í≤ÉÏûÖÎãàÎã§.\n",
    "- Í∞êÏ†ïÏùò ÏõêÏù∏Ïù¥ ÏßàÎ¨∏ ÏÜçÏóê Î™ÖÌôïÌûà ÎìúÎü¨ÎÇòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞, ÏÇ¨Ïö©ÏûêÍ∞Ä Ïä§Ïä§Î°ú Í∞êÏ†ïÏùÑ Ï†ïÎ¶¨Ìï† Ïàò ÏûàÎèÑÎ°ù **Ï∂îÍ∞Ä ÏßàÎ¨∏ÏùÑ ÌÜµÌï¥ Ïú†ÎèÑ**ÌïòÏÑ∏Ïöî.\n",
    "- Í∞êÏ†ïÏùÑ ÌÉêÏÉâÌïòÍ≥† Ìï¥ÏÜåÌï† Ïàò ÏûàÎèÑÎ°ù, ÏÉÅÎã¥ÏûêÏ≤òÎüº ÎåÄÌôîÎ•º Ïù¥ÎÅåÏñ¥Í∞ÄÏïº Ìï©ÎãàÎã§.\n",
    "\n",
    "ÎãµÎ≥Ä Íµ¨Ï°∞:\n",
    "1. Î≥¥Ìò∏ÏûêÏùò Í∞êÏ†ï ÌëúÌòÑÏóê ÏßÑÏã¨ Ïñ¥Î¶∞ Í≥µÍ∞ê\n",
    "2. Í∞êÏ†ïÏùò ÏõêÏù∏Ïù¥ Î™ÖÌôïÌïòÎã§Î©¥ ‚Üí Ïù¥Î•º Í∞ÑÍ≤∞Ìûà Ï†ïÎ¶¨ÌïòÍ≥† Í∞êÏ†ï ÏàòÏö©\n",
    "3. Í∞êÏ†ïÏùò ÏõêÏù∏Ïù¥ Î∂àÎ∂ÑÎ™ÖÌïòÎã§Î©¥ ‚Üí Ï∂îÍ∞Ä ÏßàÎ¨∏ 1~2Í∞úÎ•º ÌÜµÌï¥ Ïù¥Ïú†Î•º Ìï®Íªò ÌÉêÏÉâ\n",
    "4. Í∞êÏ†ïÏùÑ Ï†ïÎ¶¨ÌïòÍ≥†, Î∞òÎ†§Í≤¨Í≥ºÏùò ÏùºÏÉÅÏúºÎ°ú Îã§Ïãú Ïó∞Í≤∞Îê† Ïàò ÏûàÎèÑÎ°ù Í∞ÄÎ≥çÍ≥† ÌòÑÏã§Ï†ÅÏù∏ Ï°∞Ïñ∏ Ï†úÏãú\n",
    "\n",
    "- ÏÉÅÎã¥Ïùò ÏãúÏûëÏùÄ ÏïÑÎûò ÌòïÏãùÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ìï≠ÏÉÅ Î≥¥Ìò∏ÏûêÏùò Í∞êÏ†ïÏùÑ Í≥µÍ∞êÌïòÎäî Î¨∏Ïû•ÏúºÎ°ú ÏãúÏûëÌïòÏÑ∏Ïöî.\n",
    "  **\"ÏïàÎÖïÌïòÏÑ∏Ïöî! (Î∞òÎ†§Í≤¨ Ïù¥Î¶Ñ) Î≥¥Ìò∏ÏûêÎãò! (Î∞òÎ†§Í≤¨ Ïù¥Î¶Ñ)Ïùò (Í≥†ÎØº ÎÇ¥Ïö©) ÎïåÎ¨∏Ïóê Í≥†ÎØºÏù¥ ÎßéÏúºÏãúÍ≤†Ïñ¥Ïöî.\"**\n",
    "\n",
    "Î¨∏Ï≤¥ ÏßÄÏπ®:\n",
    "- ÏßÄÎÇòÏπòÍ≤å Í∞êÏÑ±Ï†ÅÏù∏ Î¨∏Ïû•, Ïû•Ìô©Ìïú ÏÑ§Î™ÖÏùÄ ÌîºÌïòÍ≥†, Îî∞ÎúªÌïòÎ©¥ÏÑúÎèÑ Ï∞®Î∂ÑÌïú Ïñ¥Ï°∞Î•º Ïú†ÏßÄÌïòÏÑ∏Ïöî.\n",
    "- ÏúÑÎ°úÎäî ÌòÑÏã§Ï†ÅÏù¥Ïñ¥Ïïº ÌïòÎ©∞, Î≥¥Ìò∏ÏûêÍ∞Ä Î∂ÄÎã¥ÏùÑ ÎäêÎÅºÏßÄ ÏïäÎèÑÎ°ù Í∞ÑÍ≤∞ÌïòÍ≤å ÎßêÌïòÏÑ∏Ïöî.\n",
    "- Î∞òÎ†§Í≤¨ÏùÄ Ï†àÎåÄÎ°ú 'Í∑∏ÎÖÄ', 'Í∑∏'Ï≤òÎüº Ïù∏Í≤©ÌôîÌïòÏßÄ ÎßêÍ≥†, Î∞òÎìúÏãú 'Î∞òÎ†§Í≤¨', 'Í∞ïÏïÑÏßÄ'Ï≤òÎüº Ï§ëÎ¶ΩÏ†ÅÏù¥Í±∞ÎÇò Î∞òÎ†§Í≤¨ Ïù¥Î¶ÑÏúºÎ°ú ÏßÄÏπ≠ÌïòÏÑ∏Ïöî.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bb733",
   "metadata": {
    "id": "7c7bb733"
   },
   "outputs": [],
   "source": [
    "# === 4. Î≤°ÌÑ∞DB Î°úÎìú ===\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectordb = FAISS.load_local(\"openai_faiss_db\", embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c113505",
   "metadata": {
    "id": "5c113505",
    "outputId": "6ed0681c-9315-4ee6-a57e-3a76174db876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê∂ Î∞òÎ†§Í≤¨ ÌñâÎèô ÏÉÅÎã¥ Ï±óÎ¥áÏûÖÎãàÎã§. 'ÏôÑÎ£å'Î•º ÏûÖÎ†•ÌïòÎ©¥ Ï¢ÖÎ£åÎê©ÎãàÎã§.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î∞òÎ†§Í≤¨ Ï¢ÖÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî:  ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥\n",
      "Î∞òÎ†§Í≤¨Ïùò Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî:  Î©îÏù¥\n",
      "\n",
      "üßë ÏÇ¨Ïö©Ïûê Í≥†ÎØº:  ÏöîÏ¶ò Ïö∞Î¶¨ Í∞ïÏïÑÏßÄÍ∞Ä ÎÇòÎßå Î≥¥Î©¥ ÎπôÎπô ÎèåÏïÑ Ïôú Í∑∏Îü∞ ÏßÄ ÏïåÏïÑ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ [Î™®Îç∏ Î∂ÑÎ•ò Ï∂úÎ†•]: Ïπ¥ÌÖåÍ≥†Î¶¨: ÏßÄÏãù ÌÉêÏÉâ\n",
      "\n",
      "üìå Î∂ÑÎ•òÎêú Ïπ¥ÌÖåÍ≥†Î¶¨: ÏßÄÏãù ÌÉêÏÉâ\n",
      "\n",
      "‚ö†Ô∏è Ïú†ÏÇ¨Ìïú Î¨∏ÏÑúÍ∞Ä ÏóÜÏñ¥ SerpAPIÎ°ú ÎåÄÏ≤¥ Í≤ÄÏÉâÏùÑ ÏàòÌñâÌï©ÎãàÎã§.\n",
      "Í≤ÄÏÉâÎêú Î¨∏ÏÑú: Î∞òÎ†§Í≤¨ ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥ Ïö∞Î¶¨ Í∞ïÏïÑÏßÄ / Í±¥Í∞ïÌïòÍ≤å Ïò§Îûò Ïò§Îûò ÏÇ¥ÏïÑÏ§ò\n",
      "ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥ ÎÇ®Ïûê Í∞ïÏïÑÏßÄ Ïù∏Îç∞ Ïã§Ï†úÎ°ú Î≥¥Î©¥ Ïó¨ÏûêÏ≤òÎüº Ïù¥ÏÅòÍ≤å ÏÉùÍ≤ºÏñ¥Ïöî ^^. ÏöîÏ¶ò Îì§Ïñ¥ÏÑú Í∞ïÏïÑÏßÄ ÏÇ¨ÏßÑÎßå Î¥êÎèÑ ÎààÎ¨ºÏù¥ ÎÇòÎÑ§Ïöî ~. ÏôúÍ∑∏Îü∞ÏßÄ Î™®Î•¥Í≤†ÎÑ§Ïöî „Ö† ...\n",
      "\n",
      "ü§ñ [ÏßÄÏãù ÌÉêÏÉâ ÏùëÎãµ]: ÏïàÎÖïÌïòÏÑ∏Ïöî! Î©îÏù¥ Î≥¥Ìò∏ÏûêÎãò! Í∞ïÏïÑÏßÄÍ∞Ä ÎÇòÎßå Î≥¥Î©¥ ÎπôÎπô ÎèåÏïÑÎäî ÌñâÎèôÏóê ÎåÄÌï¥ ÏïåÎ†§ÎìúÎ¶¥Í≤åÏöî.  \n",
      "\n",
      "Î∞òÎ†§Í≤¨Ïù¥ ÌäπÏ†ï ÏÇ¨ÎûåÏóêÍ≤å ÎπôÎπô ÎèåÎ¶¨Îäî ÌñâÎèôÏùÄ ÎåÄÎ∂ÄÎ∂Ñ **ÏÇ¨ÎûëÏùÑ ÌëúÌòÑÌïòÍ±∞ÎÇò Ìù•Î∂ÑÌïú ÏÉÅÌÉú**Ïùº Ïàò ÏûàÏñ¥Ïöî. ÌäπÌûà ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥Îäî ÏÜåÌòïÍ≤¨ÏúºÎ°ú ÏóêÎÑàÏßÄÍ∞Ä ÎßéÍ≥†, Ï£ºÏù∏ÏùÑ Ìñ•Ìïú Ïï†Ï†ïÏùÑ ÌëúÌòÑÌïòÍ∏∞ ÏúÑÌï¥ Ïù¥Îü∞ ÌñâÎèôÏùÑ Ìï† Ïàò ÏûàÏñ¥Ïöî. ÎòêÌïú, Ï£ºÏù∏ÏùÑ Î≥¥Í≥† Î∞òÏùëÌïòÎäî ÌñâÎèôÏùÄ **ÏïàÏ†ïÍ∞êÏùÑ ÎäêÎÅºÎäî ÏßïÌõÑ**Î°ú, Î©îÏù¥Í∞Ä Î≥¥Ìò∏ÏûêÎãòÏùÑ ÏïàÏ†ïÍ∞ê ÏûàÎäî Ï°¥Ïû¨Î°ú Ïù∏ÏãùÌïòÍ≥† ÏûàÏùåÏùÑ Î≥¥Ïó¨Ï£ºÎäî Í±∞ÏòàÏöî.  \n",
      "\n",
      "Ïù¥ ÌñâÎèôÏù¥ Í∞ëÏûëÏä§ÎüΩÍ≤å Î≥ÄÌïòÍ±∞ÎÇò Î∂àÏïà, Í≥µÍ≤©ÏÑ±Í≥º Ìï®Íªò ÎÇòÌÉÄÎÇúÎã§Î©¥ ÏàòÏùòÏÇ¨ÎÇò ÌñâÎèô Ï†ÑÎ¨∏Í∞ÄÏôÄ ÏÉÅÎã¥ÌïòÎäî Í≤ÉÏù¥ Ï¢ãÏßÄÎßå, ÌòÑÏû¨Îäî ÏûêÏó∞Ïä§Îü¨Ïö¥ Î∞òÏùëÏùº Í∞ÄÎä•ÏÑ±Ïù¥ ÎÜíÏïÑÏöî. Î©îÏù¥Ïùò Í±¥Í∞ïÍ≥º ÌñâÎ≥µÏùÑ ÏúÑÌï¥ Íæ∏Ï§ÄÌïú Í¥ÄÏã¨Í≥º Ïï†Ï†ïÏùÑ ÎÇòÎà†Ï£ºÏÖîÏÑú Í∞êÏÇ¨Ìï©ÎãàÎã§! üêæ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßë ÏÇ¨Ïö©Ïûê Í≥†ÎØº:  Ïôú Ïù¥Î†áÍ≤å ÎπôÎπô ÎèåÏïÑ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ [Î™®Îç∏ Î∂ÑÎ•ò Ï∂úÎ†•]: Ïπ¥ÌÖåÍ≥†Î¶¨: ÏßÄÏãù ÌÉêÏÉâ\n",
      "\n",
      "üìå Î∂ÑÎ•òÎêú Ïπ¥ÌÖåÍ≥†Î¶¨: ÏßÄÏãù ÌÉêÏÉâ\n",
      "\n",
      "‚ö†Ô∏è Ïú†ÏÇ¨Ìïú Î¨∏ÏÑúÍ∞Ä ÏóÜÏñ¥ SerpAPIÎ°ú ÎåÄÏ≤¥ Í≤ÄÏÉâÏùÑ ÏàòÌñâÌï©ÎãàÎã§.\n",
      "Í≤ÄÏÉâÎêú Î¨∏ÏÑú: ÏöîÌÅ¨ÏÖî ÌÖåÎ¶¨Ïñ¥ÏóêÏÑú ÌùîÌûà Î≥º Ïàò ÏûàÎäî ÌñâÎèô Î¨∏Ï†úÎäî Î¨¥ÏóáÏù∏Í∞ÄÏöî?\n",
      "ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥Í∞Ä Ï•êÏû°Ïù¥(ÏûëÏùÄ Í≥µÍ∞ÑÏóê Ïà®Ïñ¥ ÏûàÎäî Ï•êÏôÄ Ìï¥Ï∂©ÏùÑ Ïû°Îäî Í∞ú)Î°ú ÏÇ¨Ïö©ÎêòÏóàÎã§Îäî Í≤ÉÏùÄ ÎÑêÎ¶¨ ÏïåÎ†§ÏßÑ ÏÇ¨Ïã§ÏûÖÎãàÎã§. ¬∑ ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥Îäî Ïà≤ ÏÜç Íµ¥Ïù¥ÎÇò ÏùÄÎ∞ÄÌïú ...\n",
      "\n",
      "[Í∞ïÏïÑÏßÄÎâ¥Ïä§] ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥Ïùò ÏÑ±Í≤©Í≥º ÌäπÏßïÏùÑ ÏïåÏïÑÎ≥¥ÏïÑÏöî\n",
      "ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥Îäî ÏûëÏùÄ Í∞úÏù¥ÎØÄÎ°ú ÌïÑÏöîÌïú Ïö¥ÎèôÎüâÏùÄ Ï†ÅÍ≥†, Ïã§ÎÇ¥ÏïàÏóêÏÑúÏùò Ïö¥ÎèôÏúºÎ°úÎèÑ Ï∂©Î∂ÑÌï©ÎãàÎã§. ÏÇ∞Ï±ÖÏùÄ Ïö¥ÎèôÏù¥ Îê†ÎøêÎßå ÏïÑÎãàÎùº Îã§Î•∏ Í∞ïÏïÑÏßÄÏôÄ Í∞ÄÏ°± Ïù¥Ïô∏Ïùò ...\n",
      "\n",
      "ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥(ÏöîÌÇ§)Ïùò ÏÑ±Í≤©Í≥º ÌäπÏßï Í∑∏Î¶¨Í≥† Ïó≠ÏÇ¨ÍπåÏßÄ\n",
      "19ÏÑ∏Í∏∞ Ï§ëÏóΩÏóê ÏûâÍ∏ÄÎûúÎìú Î∂ÅÎ∂ÄÏùò 'ÏöîÌÅ¨ÏÖî' ÏßÄÏó≠ÏóêÏÑú Ï≤òÏùå ÌÉÑÏÉùÌïú Í≤ÉÏúºÎ°ú ÏïåÎ†§Ï†∏ ÏûàÍ≥† ÏÇ¨ÎÉ•Í≤¨Ïù¥ÏóàÍ∏∞Ïóê 'ÌÖåÎ¶¨Ïñ¥'ÎùºÎäî Ïù¥Î¶ÑÏù¥ Î∂ôÏñ¥ 'ÏöîÌÅ¨ÏÖîÌÖåÎ¶¨Ïñ¥'Í∞Ä ÌÉÑÏÉù ...\n"
     ]
    }
   ],
   "source": [
    "# === 6. Ï±óÎ¥á Î£®ÌîÑ ===\n",
    "print(\"üê∂ Î∞òÎ†§Í≤¨ ÌñâÎèô ÏÉÅÎã¥ Ï±óÎ¥áÏûÖÎãàÎã§. 'ÏôÑÎ£å'Î•º ÏûÖÎ†•ÌïòÎ©¥ Ï¢ÖÎ£åÎê©ÎãàÎã§.\")\n",
    "dog_breed = input(\"Î∞òÎ†§Í≤¨ Ï¢ÖÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî: \").strip()\n",
    "dog_name = input(\"Î∞òÎ†§Í≤¨Ïùò Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî: \").strip()\n",
    "\n",
    "chat_history = []\n",
    "prev_q, prev_a, prev_cate = None, None, None\n",
    "while True:\n",
    "    user_input = input(\"\\nüßë ÏÇ¨Ïö©Ïûê Í≥†ÎØº: \").strip()\n",
    "    if \"ÏôÑÎ£å\" in user_input:\n",
    "        print(\"\\n‚úÖ ÎåÄÌôîÎ•º Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
    "        break\n",
    "\n",
    "    category = classify_question(user_input, prev_q, prev_a, prev_cate)\n",
    "    print(f\"\\nüìå Î∂ÑÎ•òÎêú Ïπ¥ÌÖåÍ≥†Î¶¨: {category}\")\n",
    "    system_msg = {\"role\": \"system\", \"content\": PROMPT_MAP[category]}\n",
    "\n",
    "    # üîç RAG Í≤ÄÏÉâ\n",
    "    retrieved_docs_with_score = vectordb.similarity_search_with_score(user_input, k=3)\n",
    "    # Ïú†ÏÇ¨ÎèÑ Í∏∞Ï§Ä ÏÑ§Ï†ï (cosine similarity Í∏∞Ï§Ä, Ï†êÏàòÍ∞Ä ÎÜíÏùÑÏàòÎ°ù Ïú†ÏÇ¨ÎèÑ ÎÇÆÏùå. Î≥¥ÌÜµ 0.7 Ïù¥ÌïòÍ∞Ä Ïú†ÏùòÎØ∏)\n",
    "    threshold = 1.0\n",
    "    filtered_docs = [\n",
    "    doc.page_content\n",
    "    for doc, score in retrieved_docs_with_score\n",
    "    if score <= threshold\n",
    "    ]\n",
    "    if filtered_docs:\n",
    "        retrieved_context = \"\\n\\n\".join(filtered_docs)\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Ïú†ÏÇ¨Ìïú Î¨∏ÏÑúÍ∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
    "\n",
    "    print(\"Í≤ÄÏÉâÎêú Î¨∏ÏÑú:\", retrieved_context)\n",
    "\n",
    "    user_message = f\"\"\"Í¥ÄÎ†® Ï†ïÎ≥¥:\n",
    "    {retrieved_context}\n",
    "\n",
    "    ÏÇ¨Ïö©Ïûê Î∞òÎ†§Í≤¨ Ï†ïÎ≥¥:\n",
    "    Í≤¨Ï¢Ö: {dog_breed}\n",
    "    Ïù¥Î¶Ñ: {dog_name}\n",
    "\n",
    "    ÏßàÎ¨∏:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    # ÏµúÍ∑º ÎåÄÌôî 9Í∞úÎßå Ïú†ÏßÄ + system ÌîÑÎ°¨ÌîÑÌä∏\n",
    "    messages = [system_msg] + chat_history[-9:]\n",
    "\n",
    "    prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=True)\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2048,\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            top_k=20,\n",
    "            do_sample=True\n",
    "        )\n",
    "\n",
    "    output_ids = outputs[0][inputs.input_ids.shape[-1]:].tolist()\n",
    "\n",
    "    # ÏÇ¨Í≥†Î™®Îìú </think> Î∂ÑÎ¶¨\n",
    "    try:\n",
    "        end_token_id = 151668  # </think>\n",
    "        index = len(output_ids) - output_ids[::-1].index(end_token_id)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "\n",
    "    thinking = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip()\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip()\n",
    "\n",
    "    # thinkingÏùÄ Ï†ÄÏû• x\n",
    "    print(f\"\\nü§ñ [{category} ÏùëÎãµ]: {content}\")\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "    prev_q, prev_a, prev_cate = user_input, content, category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3329e46-b6fd-4e21-816a-ef99401353a9",
   "metadata": {
    "id": "c3329e46-b6fd-4e21-816a-ef99401353a9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766a2d1-c0bf-4f7a-9557-7a873723ad61",
   "metadata": {
    "id": "f766a2d1-c0bf-4f7a-9557-7a873723ad61"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
